# Pixabayé£Ÿç‰©æ‘„å½±å›¾ç‰‡æ™ºèƒ½æ¨èç³»ç»Ÿä½¿ç”¨æŒ‡å—

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

æœ¬ç³»ç»ŸåŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼Œç”¨äºä»Pixabayé£Ÿç‰©æ‘„å½±é¡µé¢è·å–é«˜è´¨é‡å›¾ç‰‡ï¼Œå¹¶é€šè¿‡æ™ºèƒ½è¯†åˆ«ä¸º"ä¸­åˆåƒä»€ä¹ˆ"åŠŸèƒ½æ¨èåˆé€‚çš„é£Ÿç‰©å›¾ç‰‡ï¼š

1. **å®Œæ•´ç‰ˆçˆ¬è™«** (`pixabay_food_photography_crawler.py`) - ä½¿ç”¨OpenCVè¿›è¡Œå›¾åƒåˆ†æ
2. **ç®€åŒ–ç‰ˆçˆ¬è™«** (`pixabay_food_photography_simple.py`) - ä½¿ç”¨è½»é‡çº§å…³é”®è¯åŒ¹é…

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ç®€åŒ–ç‰ˆï¼ˆæ¨èï¼‰

ç®€åŒ–ç‰ˆä¸éœ€è¦å®‰è£…OpenCVï¼Œä¾èµ–æ›´å°‘ï¼Œè¿è¡Œæ›´å¿«ï¼š

```bash
# å®‰è£…ä¾èµ–
pip install requests beautifulsoup4 pillow

# è¿è¡Œç®€åŒ–ç‰ˆçˆ¬è™«
python pixabay_food_photography_simple.py
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨å®Œæ•´ç‰ˆ

å®Œæ•´ç‰ˆæä¾›æ›´ç²¾ç¡®çš„å›¾åƒåˆ†æï¼Œä½†éœ€è¦å®‰è£…æ›´å¤šä¾èµ–ï¼š

```bash
# å®‰è£…ä¾èµ–
pip install requests beautifulsoup4 pillow opencv-python numpy

# è¿è¡Œå®Œæ•´ç‰ˆçˆ¬è™«
python pixabay_food_photography_crawler.py
```

## ğŸ“‹ åŠŸèƒ½ç‰¹æ€§

### ğŸ” æ™ºèƒ½å›¾ç‰‡è¯†åˆ«
- **å¤šç»´åº¦åŒ¹é…**ï¼šåŸºäºæ ‡é¢˜ã€æ ‡ç­¾ã€URLç‰¹å¾è¿›è¡Œç»¼åˆåˆ†æ
- **å…³é”®è¯æƒé‡**ï¼šå®Œå…¨åŒ¹é…(5åˆ†) > éƒ¨åˆ†åŒ¹é…(3åˆ†) > ç›¸å…³åŒ¹é…(1åˆ†)
- **ç½®ä¿¡åº¦è¯„åˆ†**ï¼šè‡ªåŠ¨è®¡ç®—åŒ¹é…è´¨é‡ï¼Œåªä¿ç•™é«˜è´¨é‡æ¨è

### ğŸ½ï¸ é£Ÿç‰©åˆ†ç±»ç³»ç»Ÿ
- **ä¸­é¤**ï¼š26ç§ç»å…¸èœå“ï¼ˆéº»å©†è±†è…ã€å®«ä¿é¸¡ä¸ã€çº¢çƒ§è‚‰ç­‰ï¼‰
- **è¥¿é¤**ï¼š15ç§ç»å…¸èœå“ï¼ˆæ„å¤§åˆ©é¢ã€æŠ«è¨ã€æ±‰å ¡åŒ…ç­‰ï¼‰
- **æ—¥æ–™**ï¼š7ç§ç»å…¸èœå“ï¼ˆå¯¿å¸ã€æ‹‰é¢ã€å¤©å¦‡ç½—ç­‰ï¼‰
- **éŸ©æ–™**ï¼š7ç§ç»å…¸èœå“ï¼ˆéŸ©å¼çƒ¤è‚‰ã€æ³¡èœæ±¤ç­‰ï¼‰
- **æ³°é¤**ï¼š6ç§ç»å…¸èœå“ï¼ˆæ³°å¼å’–å–±ã€å†¬é˜´åŠŸç­‰ï¼‰

### ğŸ“Š è‡ªåŠ¨æ›´æ–°æœºåˆ¶
- **å®æ—¶çˆ¬å–**ï¼šç›´æ¥ä»Pixabayé£Ÿç‰©æ‘„å½±é¡µé¢è·å–æœ€æ–°å›¾ç‰‡
- **æ™ºèƒ½ç­›é€‰**ï¼šè¿‡æ»¤ä½è´¨é‡å›¾ç‰‡ï¼Œåªä¿ç•™é«˜è´¨é‡é£Ÿç‰©æ‘„å½±
- **è‡ªåŠ¨æ˜ å°„**ï¼šè‡ªåŠ¨æ›´æ–°`comprehensive_food_images.py`æ–‡ä»¶

## ğŸ› ï¸ è¯¦ç»†ä½¿ç”¨è¯´æ˜

### 1. ç³»ç»Ÿé…ç½®

#### ç¯å¢ƒè¦æ±‚
```python
# åŸºç¡€ä¾èµ–
requests>=2.25.1
beautifulsoup4>=4.9.3
pillow>=8.0.0

# å®Œæ•´ç‰ˆé¢å¤–ä¾èµ–
opencv-python>=4.5.0
numpy>=1.19.0
```

#### æ–‡ä»¶ç»“æ„
```
QAToolBox/
â”œâ”€â”€ pixabay_food_photography_simple.py      # ç®€åŒ–ç‰ˆçˆ¬è™«
â”œâ”€â”€ pixabay_food_photography_crawler.py     # å®Œæ•´ç‰ˆçˆ¬è™«
â”œâ”€â”€ update_food_images_with_pixabay.py      # APIç‰ˆæœ¬æ›´æ–°å™¨
â”œâ”€â”€ apps/tools/services/
â”‚   â””â”€â”€ comprehensive_food_images.py        # å›¾ç‰‡æ˜ å°„æ–‡ä»¶
â””â”€â”€ è¾“å‡ºæ–‡ä»¶/
    â”œâ”€â”€ pixabay_food_simple_results.json    # ç®€åŒ–ç‰ˆç»“æœ
    â”œâ”€â”€ pixabay_food_analysis_results.json  # å®Œæ•´ç‰ˆç»“æœ
    â”œâ”€â”€ PIXABAY_FOOD_SIMPLE_REPORT.md       # ç®€åŒ–ç‰ˆæŠ¥å‘Š
    â””â”€â”€ PIXABAY_FOOD_ANALYSIS_REPORT.md     # å®Œæ•´ç‰ˆæŠ¥å‘Š
```

### 2. è¿è¡Œæµç¨‹

#### ç®€åŒ–ç‰ˆè¿è¡Œæµç¨‹
```python
# 1. çˆ¬å–Pixabayé£Ÿç‰©æ‘„å½±é¡µé¢
images = crawler.crawl_food_photography_page()

# 2. åˆ†æå›¾ç‰‡ç‰¹å¾ï¼ˆåŸºäºæ–‡æœ¬å’ŒURLï¼‰
analyzed_images = []
for image_info in images:
    result = crawler.analyze_image_simple(image_info)
    if result.get('success'):
        analyzed_images.append(result)

# 3. ç”Ÿæˆé£Ÿç‰©æ¨è
recommendations = crawler.generate_food_recommendations(analyzed_images)

# 4. åˆ›å»ºå›¾ç‰‡æ˜ å°„
image_mapping = crawler.create_enhanced_image_mapping(recommendations)

# 5. è‡ªåŠ¨æ›´æ–°æ–‡ä»¶
update_comprehensive_food_images(image_mapping)
```

#### å®Œæ•´ç‰ˆè¿è¡Œæµç¨‹
```python
# 1. çˆ¬å–Pixabayé£Ÿç‰©æ‘„å½±é¡µé¢
images = crawler.crawl_food_photography_page()

# 2. ä¸‹è½½å¹¶åˆ†æå›¾ç‰‡ï¼ˆä½¿ç”¨OpenCVï¼‰
analyzed_images = []
for image_info in images:
    result = crawler.download_and_analyze_image(image_info)
    if result.get('success'):
        analyzed_images.append(result)

# 3. ç”Ÿæˆé£Ÿç‰©æ¨èï¼ˆåŸºäºå›¾åƒç‰¹å¾ï¼‰
recommendations = crawler.generate_food_recommendations(analyzed_images)

# 4. åˆ›å»ºå›¾ç‰‡æ˜ å°„
image_mapping = crawler.create_enhanced_image_mapping(recommendations)
```

### 3. é…ç½®é€‰é¡¹

#### çˆ¬è™«é…ç½®
```python
class SimplePixabayFoodCrawler:
    def __init__(self):
        # åŸºç¡€URLé…ç½®
        self.base_url = "https://pixabay.com"
        self.search_url = "https://pixabay.com/photos/search/food%20photography/"
        
        # è¯·æ±‚å¤´é…ç½®
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36...',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            # ... å…¶ä»–é…ç½®
        }
        
        # å…³é”®è¯æƒé‡é…ç½®
        self.keyword_weights = {
            'exact_match': 5,    # å®Œå…¨åŒ¹é…æƒé‡
            'partial_match': 3,  # éƒ¨åˆ†åŒ¹é…æƒé‡
            'related_match': 1,  # ç›¸å…³åŒ¹é…æƒé‡
        }
```

#### åˆ†æå‚æ•°é…ç½®
```python
def run_complete_analysis(self, max_images: int = 30) -> Dict:
    """
    è¿è¡Œå®Œæ•´åˆ†ææµç¨‹
    
    Args:
        max_images: æœ€å¤§åˆ†æå›¾ç‰‡æ•°é‡ï¼ˆé»˜è®¤30å¼ ï¼‰
    """
    
def match_food_types(self, analysis: Dict) -> List[Dict]:
    """
    åŒ¹é…é£Ÿç‰©ç±»å‹
    
    Args:
        analysis: å›¾ç‰‡åˆ†æç»“æœ
        
    Returns:
        åŒ¹é…çš„é£Ÿç‰©ç±»å‹åˆ—è¡¨ï¼ˆè¿”å›å‰5ä¸ªæœ€ä½³åŒ¹é…ï¼‰
    """
```

### 4. è¾“å‡ºç»“æœ

#### JSONç»“æœæ–‡ä»¶
```json
{
  "recommendations": {
    "chinese": [
      {
        "food_name": "éº»å©†è±†è…",
        "image_url": "https://pixabay.com/get/...",
        "confidence": 0.85,
        "matched_keywords": ["tofu", "spicy"],
        "image_title": "Spicy Mapo Tofu",
        "score": 12
      }
    ]
  },
  "image_mapping": {
    "éº»å©†è±†è…": "https://pixabay.com/get/...?w=500&h=400&fit=crop&crop=center"
  },
  "stats": {
    "total_images_crawled": 45,
    "total_images_analyzed": 30,
    "total_recommendations": 28,
    "image_mapping_count": 28
  }
}
```

#### åˆ†ææŠ¥å‘Š
```markdown
# Pixabayé£Ÿç‰©æ‘„å½±æ™ºèƒ½åˆ†ææŠ¥å‘Š

## ğŸ“Š åˆ†æç»Ÿè®¡
- **çˆ¬å–å›¾ç‰‡æ•°é‡**: 45
- **åˆ†æå›¾ç‰‡æ•°é‡**: 30
- **æ¨èæ•°é‡**: 28
- **å›¾ç‰‡æ˜ å°„æ•°é‡**: 28

## ğŸ½ï¸ èœç³»æ¨èåˆ†å¸ƒ
### CHINESE (12ä¸ªæ¨è)
- **éº»å©†è±†è…** (ç½®ä¿¡åº¦: 0.85, åˆ†æ•°: 12)
  - åŒ¹é…å…³é”®è¯: tofu, spicy
  - å›¾ç‰‡æ ‡é¢˜: Spicy Mapo Tofu
```

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰é£Ÿç‰©å…³é”®è¯
```python
# åœ¨çˆ¬è™«ç±»ä¸­ä¿®æ”¹food_keywordså­—å…¸
self.food_keywords = {
    'chinese': {
        'æ–°èœå“': ['new dish', 'custom keyword', 'ä¸­æ–‡å…³é”®è¯'],
        # ... å…¶ä»–èœå“
    }
}
```

### è°ƒæ•´åŒ¹é…é˜ˆå€¼
```python
# ä¿®æ”¹ç½®ä¿¡åº¦é˜ˆå€¼
if match['confidence'] > 0.2:  # é»˜è®¤0.2ï¼Œå¯è°ƒæ•´ä¸º0.1-0.5
    recommendations[match['cuisine']].append(...)
```

### è‡ªå®šä¹‰å›¾ç‰‡ä¼˜åŒ–å‚æ•°
```python
# ä¿®æ”¹å›¾ç‰‡URLä¼˜åŒ–å‚æ•°
if '?' not in image_url:
    image_url += '?w=500&h=400&fit=crop&crop=center'  # å¯è°ƒæ•´å°ºå¯¸å’Œè£å‰ªæ–¹å¼
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

### 1. ç½‘ç»œè¯·æ±‚é™åˆ¶
- ç³»ç»Ÿå†…ç½®è¯·æ±‚å»¶è¿Ÿï¼Œé¿å…å¯¹PixabayæœåŠ¡å™¨é€ æˆå‹åŠ›
- å»ºè®®åœ¨éé«˜å³°æ—¶æ®µè¿è¡Œï¼Œæé«˜æˆåŠŸç‡

### 2. å›¾ç‰‡è´¨é‡æ§åˆ¶
- ç³»ç»Ÿè‡ªåŠ¨è¿‡æ»¤ä½è´¨é‡å›¾ç‰‡
- åªä¿ç•™ç½®ä¿¡åº¦è¾ƒé«˜çš„æ¨è
- å›¾ç‰‡URLè‡ªåŠ¨ä¼˜åŒ–ä¸º500x400åƒç´ 

### 3. ç‰ˆæƒå®‰å…¨
- æ‰€æœ‰å›¾ç‰‡å‡æ¥è‡ªPixabayå…è´¹å›¾ç‰‡åº“
- å›¾ç‰‡å‡ä¸ºå…è´¹å•†ç”¨å›¾ç‰‡
- å»ºè®®åœ¨ä½¿ç”¨æ—¶ä¿ç•™Pixabayç‰ˆæƒä¿¡æ¯

### 4. é”™è¯¯å¤„ç†
- ç³»ç»Ÿå…·å¤‡å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶
- ç½‘ç»œå¼‚å¸¸æ—¶è‡ªåŠ¨é‡è¯•
- å›¾ç‰‡åˆ†æå¤±è´¥æ—¶è·³è¿‡ï¼Œä¸å½±å“æ•´ä½“æµç¨‹

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†
```python
# å¯ä»¥è°ƒæ•´max_imageså‚æ•°æ§åˆ¶å¤„ç†æ•°é‡
results = crawler.run_complete_analysis(max_images=50)  # å¤„ç†50å¼ å›¾ç‰‡
```

### 2. å¹¶å‘å¤„ç†ï¼ˆé«˜çº§ï¼‰
```python
# å¯ä»¥æ·»åŠ å¤šçº¿ç¨‹æ”¯æŒæé«˜å¤„ç†é€Ÿåº¦
import concurrent.futures

def analyze_images_parallel(images, max_workers=4):
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(crawler.analyze_image_simple, img) for img in images]
        results = [future.result() for future in concurrent.futures.as_completed(futures)]
    return results
```

### 3. ç¼“å­˜æœºåˆ¶
```python
# å¯ä»¥æ·»åŠ ç»“æœç¼“å­˜ï¼Œé¿å…é‡å¤åˆ†æ
import pickle

def save_cache(results, filename='food_analysis_cache.pkl'):
    with open(filename, 'wb') as f:
        pickle.dump(results, f)

def load_cache(filename='food_analysis_cache.pkl'):
    try:
        with open(filename, 'rb') as f:
            return pickle.load(f)
    except FileNotFoundError:
        return None
```

## ğŸ”„ å®šæœŸæ›´æ–°

### è‡ªåŠ¨åŒ–è„šæœ¬
```bash
#!/bin/bash
# åˆ›å»ºå®šæ—¶ä»»åŠ¡è„šæœ¬

# æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œæ›´æ–°
0 2 * * * cd /path/to/QAToolBox && python pixabay_food_photography_simple.py

# æˆ–è€…æ¯å‘¨è¿è¡Œä¸€æ¬¡
0 2 * * 0 cd /path/to/QAToolBox && python pixabay_food_photography_simple.py
```

### ç›‘æ§å’Œæ—¥å¿—
```python
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('food_analysis.log'),
        logging.StreamHandler()
    ]
)

# åœ¨çˆ¬è™«ä¸­æ·»åŠ æ—¥å¿—
logging.info(f"å¼€å§‹åˆ†æå›¾ç‰‡: {image_info.get('title', 'Unknown')}")
logging.warning(f"å›¾ç‰‡åˆ†æå¤±è´¥: {e}")
logging.info(f"åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(results)} å¼ å›¾ç‰‡")
```

## ğŸ‰ æ€»ç»“

é€šè¿‡ä½¿ç”¨Pixabayé£Ÿç‰©æ‘„å½±å›¾ç‰‡æ™ºèƒ½æ¨èç³»ç»Ÿï¼Œæ‚¨å¯ä»¥ï¼š

1. **è‡ªåŠ¨è·å–é«˜è´¨é‡é£Ÿç‰©å›¾ç‰‡**ï¼šç›´æ¥ä»Pixabayé£Ÿç‰©æ‘„å½±é¡µé¢çˆ¬å–
2. **æ™ºèƒ½åŒ¹é…é£Ÿç‰©ç±»å‹**ï¼šä½¿ç”¨å¤šç»´åº¦åˆ†æç®—æ³•ç²¾ç¡®åŒ¹é…
3. **è‡ªåŠ¨æ›´æ–°å›¾ç‰‡åº“**ï¼šä¸€é”®æ›´æ–°"ä¸­åˆåƒä»€ä¹ˆ"åŠŸèƒ½çš„å›¾ç‰‡æ˜ å°„
4. **ä¿æŒå›¾ç‰‡è´¨é‡**ï¼šåªæ¨èé«˜è´¨é‡ã€é«˜ç½®ä¿¡åº¦çš„å›¾ç‰‡
5. **æ”¯æŒå¤šç§èœç³»**ï¼šæ¶µç›–ä¸­é¤ã€è¥¿é¤ã€æ—¥æ–™ã€éŸ©æ–™ã€æ³°é¤ç­‰

ç³»ç»Ÿè®¾è®¡è½»é‡çº§ä¸”æ˜“äºä½¿ç”¨ï¼Œæ¨èä½¿ç”¨ç®€åŒ–ç‰ˆè¿›è¡Œæ—¥å¸¸æ›´æ–°ï¼Œå®Œæ•´ç‰ˆç”¨äºæ·±åº¦åˆ†æå’Œä¼˜åŒ–ã€‚
