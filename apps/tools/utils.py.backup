import os
import requests
from ratelimit import limits, sleep_and_retry
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from django_ratelimit.decorators import ratelimit

# 从环境变量获取配置
# 确保在模块导入时加载环境变量
from dotenv import load_dotenv
import os

# 尝试加载 .env 文件
env_paths = [
    os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env'),
    os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'),
    os.path.join(os.path.dirname(__file__), '.env'),
]

for env_path in env_paths:
    if os.path.exists(env_path):
        load_dotenv(env_path)
        break

DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')

API_RATE_LIMIT = os.getenv('API_RATE_LIMIT', '10/minute')

# 解析速率限制配置
try:
    RATE_LIMIT_CALLS, RATE_LIMIT_PERIOD = API_RATE_LIMIT.split('/')
    RATE_LIMIT_PERIOD = {'minute': 60, 'hour': 3600}[RATE_LIMIT_PERIOD.lower()]
except (ValueError, KeyError):
    RATE_LIMIT_CALLS = 10
    RATE_LIMIT_PERIOD = 60


class DeepSeekClient:
    API_BASE_URL = "https://api.deepseek.com/v1/chat/completions"
    TIMEOUT = 600  # 延长超时时间（秒），适应长内容生成
    MAX_RETRY_ATTEMPTS = 3  # 最大续生成次数 - 修复类属性定义位置

    def __init__(self):
        self.api_key = DEEPSEEK_API_KEY
        if not self.api_key:
            raise ValueError("""
DEEPSEEK_API_KEY 未在环境变量中设置！

解决方案：
1. 在项目根目录创建 .env 文件
2. 在 .env 文件中添加：DEEPSEEK_API_KEY=your_actual_api_key_here
3. 或者直接在系统环境变量中设置 DEEPSEEK_API_KEY

示例 .env 文件内容：
DEEPSEEK_API_KEY=sk-your-actual-api-key-here
API_RATE_LIMIT=10/minute
            """.strip())

    @sleep_and_retry
    @limits(calls=int(RATE_LIMIT_CALLS), period=int(RATE_LIMIT_PERIOD))
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((requests.exceptions.Timeout, requests.exceptions.ConnectionError))
    )
    def generate_test_cases(self, requirement: str, user_prompt: str, is_batch: bool = False,
                            batch_id: int = 0, total_batches: int = 1) -> str:
        """
        生成测试用例，支持智能批量生成
        
        :param requirement: 产品需求
        :param user_prompt: 用户提示词模板
        :param is_batch: 是否为批量生成模式
        :param batch_id: 当前批次ID（从0开始）
        :param total_batches: 总批次数
        :return: 生成的测试用例内容
        """
        if not requirement or not user_prompt:
            raise ValueError("需求内容和提示词模板不能为空")

        # 优化提示词，减少 token 占用
        full_prompt = user_prompt.format(
            requirement=requirement,
            format="使用Markdown：# 场景 - 用例"
        )

        # 简化的批次说明
        batch_note = f"\n批次：{batch_id + 1}/{total_batches}" if is_batch else ""

        full_prompt += f"""
要求：
1. 每个模块至少10个用例，禁止省略
2. 覆盖正常、边界、异常场景
3. 包含步骤和预期结果
4. 内容完整无遗漏
{batch_note}
        """

        # 使用更高效的模型和参数
        payload = {
            "model": "deepseek-chat",  # 使用更稳定的模型
            "messages": [
                {"role": "system",
                 "content": "专业测试工程师，生成完整测试用例，Markdown格式。"},
                {"role": "user", "content": full_prompt}
            ],
            "temperature": 0.3,  # 降低温度提高一致性
            "max_tokens": 8192,  # 使用更合理的 token 限制
            "stream": False
        }

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        try:
            response = requests.post(
                self.API_BASE_URL,
                json=payload,
                headers=headers,
                timeout=self.TIMEOUT
            )
            response.raise_for_status()
            result = response.json()

            # 检查是否达到令牌限制，如果是则请求继续生成
            if result.get('choices', [{}])[0].get('finish_reason') == 'length':
                # 传递批量参数进行续生成
                return self._continue_generation(
                    result,
                    full_prompt,
                    is_batch=is_batch,
                    batch_id=batch_id,
                    total_batches=total_batches,
                    retry_count=0
                )

            return result['choices'][0]['message']['content']
        except requests.exceptions.RequestException as e:
            error_detail = f"状态码: {response.status_code}" if 'response' in locals() else "无状态码"
            raise Exception(f"API请求失败: {str(e)} ({error_detail})")

    def _continue_generation(self, initial_result, prompt, is_batch: bool, batch_id: int,
                             total_batches: int, retry_count: int) -> str:
        """智能续生成，确保内容完整性"""
        # 超过最大重试次数则返回已生成内容
        if retry_count >= self.MAX_RETRY_ATTEMPTS:
            return initial_result['choices'][0']['message']['content']

        # 获取已生成的内容
        current_content = initial_result['choices'][0]['message']['content']
        
        # 智能续生成提示词
        continuation_prompt = self._generate_continuation_prompt(current_content, prompt)
        
        # 构建对话历史
        message_history = [
            {"role": "system", "content": "专业测试工程师，继续生成测试用例，保持格式一致。"},
            {"role": "user", "content": continuation_prompt}
        ]

        # 继续生成 payload
        payload = {
            "model": "deepseek-chat",
            "messages": message_history,
            "temperature": 0.3,
            "max_tokens": 8192,
            "stream": False
        }

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        try:
            response = requests.post(
                self.API_BASE_URL,
                json=payload,
                headers=headers,
                timeout=self.TIMEOUT
            )
            response.raise_for_status()
            result = response.json()
            additional_content = result['choices'][0]['message']['content']

            # 递归检查是否还需要继续生成（增加重试计数）
            if result.get('choices', [{}])[0].get('finish_reason') == 'length':
                return self._continue_generation(
                    result,
                    prompt,
                    is_batch=is_batch,
                    batch_id=batch_id,
                    total_batches=total_batches,
                    retry_count=retry_count + 1
                )

            return current_content + additional_content
        except Exception as e:
            # 续生成失败时返回已生成内容
            return current_content

    def generate_redbook_content(self, prompt: str) -> str:
        """调用DeepSeek接口生成小红书文案（支持图像描述）"""
        payload = {
            "model": "deepseek-vl",  # 假设使用支持图像的模型
            "messages": [
                {"role": "system", "content": "你是小红书内容专家，擅长根据图片生成吸引人的标题和文案。"},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.8,
            "max_tokens": 2048,
            "stream": False
        }

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        try:
            response = requests.post(
                self.API_BASE_URL,
                json=payload,
                headers=headers,
                timeout=self.TIMEOUT
            )
            response.raise_for_status()
            return response.json()['choices'][0]['message']['content']
        except Exception as e:
            raise Exception(f"图像识别/文案生成失败: {str(e)}")


    def _is_content_complete(self, content: str) -> bool:
        """检查生成的内容是否完整"""
        if not content:
            return False
        
        # 检查是否以完整的测试用例结尾
        lines = content.strip().split('\n')
        if not lines:
            return False
        
        # 检查最后几行是否包含完整的测试用例结构
        last_lines = lines[-3:] if len(lines) >= 3 else lines
        
        # 如果最后一行是空行或者以不完整的句子结尾，认为不完整
        if not last_lines[-1].strip():
            return False
        
        # 检查是否包含预期的结束标记
        content_lower = content.lower()
        incomplete_indicators = [
            '未完待续', '待续', '...', '等等', '省略', '此处省略',
            'to be continued', '未完', '待补充'
        ]
        
        for indicator in incomplete_indicators:
            if indicator in content_lower:
                return False
        
        return True

    def _generate_continuation_prompt(self, current_content: str, original_prompt: str) -> str:
        """生成智能续生成提示词"""
        # 提取当前内容的最后部分作为上下文
        lines = current_content.strip().split('\n')
        context_lines = lines[-10:] if len(lines) >= 10 else lines  # 取最后10行作为上下文
        context = '\n'.join(context_lines)
        
        # 分析当前内容的结构
        sections = []
        current_section = None
        for line in lines:
            if line.startswith('#'):
                current_section = line.lstrip('# ').strip()
                sections.append(current_section)
        
        continuation_prompt = f"""
请继续生成测试用例，保持与现有内容的一致性。

当前内容结构：
{chr(10).join([f"- {section}" for section in sections[-3:]])}

最后的内容上下文：
{context}

请继续生成：
1. 如果当前场景未完成，请继续完成该场景的测试用例
2. 如果当前场景已完成，请开始下一个场景
3. 保持相同的格式和详细程度
4. 确保每个测试用例都包含完整的步骤和预期结果

原始需求：{original_prompt}
        """
        
        return continuation_prompt.strip()


# 针对视图的用户级限频装饰器（1分钟最多3次请求）
def user_ratelimit(view_func):
    @ratelimit(key='user', rate='3/m', method='POST', block=True)
    def wrapper(request, *args, **kwargs):
        return view_func(request, *args, **kwargs)

    return wrapper
